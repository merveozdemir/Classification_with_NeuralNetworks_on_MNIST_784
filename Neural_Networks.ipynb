{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verinin train ve test datası olarak ayrılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X / 255\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yapay sinir ağı  algoritmasının manuel olarak en iyi parametrelerinin bulunması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPClassifier function in Scikit-learn Library is used. I tried different parameters of activation functions, regularization, numbers of hidden units and numbers of hidden layers to find the optimal model for classifying the dataset correctly.\n",
    "\n",
    "A neural network needs an activation function, hidden layers and regularization parameters. I gave different parameters of each one. The parameters that I gave are shown below:\n",
    "\n",
    "• Activation Functions : Relu, Tanh, Logistic\n",
    "\n",
    "• Solver Functions (Optional): Lbfgs, Adam\n",
    "\n",
    "• Alpha values: (0.01, 0.1, 1.0, 5.0)\n",
    "\n",
    "• Hidden layer sizes: (1,2)\n",
    "\n",
    "• Hidden layer units: (10, 50, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layer and units [10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.922\n",
      "Test_score: 0.911\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.967\n",
      "Test_score: 0.935\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.963\n",
      "Test_score: 0.929\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.969\n",
      "Test_score: 0.931\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.955\n",
      "Test_score: 0.928\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.964\n",
      "Test_score: 0.936\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.923\n",
      "Test_score: 0.911\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.956\n",
      "Test_score: 0.936\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.963\n",
      "Test_score: 0.929\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.962\n",
      "Test_score: 0.939\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.956\n",
      "Test_score: 0.930\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.946\n",
      "Test_score: 0.933\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.922\n",
      "Test_score: 0.910\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.936\n",
      "Test_score: 0.929\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.963\n",
      "Test_score: 0.931\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.940\n",
      "Test_score: 0.932\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.963\n",
      "Test_score: 0.937\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.851\n",
      "Test_score: 0.846\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.921\n",
      "Test_score: 0.910\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.895\n",
      "Test_score: 0.889\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.963\n",
      "Test_score: 0.933\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.892\n",
      "Test_score: 0.887\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.960\n",
      "Test_score: 0.939\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.112\n",
      "Test_score: 0.113\n",
      "\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "#hidden layer and units [10,10]\n",
    "for this_alpha in [0.01, 0.1, 1.0, 5.0]:\n",
    "    for this_activation in ['relu', 'tanh', 'logistic']:\n",
    "        for this_solver in ['lbfgs', 'adam']:\n",
    "            clf = MLPClassifier(solver=this_solver, \n",
    "                        activation = this_activation,\n",
    "                        alpha = this_alpha,\n",
    "                        hidden_layer_sizes = [10, 10], \n",
    "                        random_state = 0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            title = 'Dataset 2: NN classifier, alpha = {:.3f} '.format(this_alpha)\n",
    "            print(\"with   |  Solver: \", this_solver , \" | Activation: \" , this_activation,\" | Alpha: \", this_alpha)\n",
    "            print(title)\n",
    "            print(\"\\nTrain_score: %.3f\" % clf.score(X_train, y_train))\n",
    "            print(\"Test_score: %.3f\\n\" % clf.score(X_test, y_test))\n",
    "            print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  hidden layer and units 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.918\n",
      "Test_score: 0.903\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.961\n",
      "Test_score: 0.935\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.960\n",
      "Test_score: 0.927\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.962\n",
      "Test_score: 0.927\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.957\n",
      "Test_score: 0.927\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.957\n",
      "Test_score: 0.934\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.918\n",
      "Test_score: 0.902\n",
      "\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.954\n",
      "Test_score: 0.938\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.959\n",
      "Test_score: 0.928\n",
      "\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.956\n",
      "Test_score: 0.937\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.957\n",
      "Test_score: 0.928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.936\n",
      "Test_score: 0.922\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.918\n",
      "Test_score: 0.902\n",
      "\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.934\n",
      "Test_score: 0.925\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.960\n",
      "Test_score: 0.929\n",
      "\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.926\n",
      "Test_score: 0.917\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.958\n",
      "Test_score: 0.931\n",
      "\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.899\n",
      "Test_score: 0.891\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.918\n",
      "Test_score: 0.902\n",
      "\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.902\n",
      "Test_score: 0.893\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.959\n",
      "Test_score: 0.931\n",
      "\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.896\n",
      "Test_score: 0.889\n",
      "\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.952\n",
      "Test_score: 0.933\n",
      "\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.808\n",
      "Test_score: 0.808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hidden layer and units 10\n",
    "for this_alpha in [0.01, 0.1, 1.0, 5.0]:\n",
    "    for this_activation in ['relu', 'tanh', 'logistic']:\n",
    "        for this_solver in ['lbfgs', 'adam']:\n",
    "            clf = MLPClassifier(solver=this_solver, \n",
    "                        activation = this_activation,\n",
    "                        alpha = this_alpha,\n",
    "                        hidden_layer_sizes = 10, \n",
    "                        random_state = 0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            title = 'Dataset 2: NN classifier, alpha = {:.3f} '.format(this_alpha)\n",
    "            print(\"with   |  Solver: \", this_solver , \" | Activation: \" , this_activation,\" | Alpha: \", this_alpha)\n",
    "            print(title)\n",
    "            print(\"\\nTrain_score: %.3f\" % clf.score(X_train, y_train))\n",
    "            print(\"Test_score: %.3f\\n\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layer and units [10,10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.920\n",
      "Test_score: 0.907\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.969\n",
      "Test_score: 0.936\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.963\n",
      "Test_score: 0.932\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.974\n",
      "Test_score: 0.933\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.917\n",
      "Test_score: 0.897\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.959\n",
      "Test_score: 0.928\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.923\n",
      "Test_score: 0.912\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.961\n",
      "Test_score: 0.939\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.963\n",
      "Test_score: 0.933\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.970\n",
      "Test_score: 0.942\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.927\n",
      "Test_score: 0.909\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.948\n",
      "Test_score: 0.936\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.923\n",
      "Test_score: 0.913\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.948\n",
      "Test_score: 0.936\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.964\n",
      "Test_score: 0.933\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.950\n",
      "Test_score: 0.937\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.934\n",
      "Test_score: 0.912\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.112\n",
      "Test_score: 0.113\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.924\n",
      "Test_score: 0.910\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.887\n",
      "Test_score: 0.881\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.963\n",
      "Test_score: 0.935\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.904\n",
      "Test_score: 0.899\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.953\n",
      "Test_score: 0.932\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.112\n",
      "Test_score: 0.113\n",
      "\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "#hidden layer and units [10,10,10]\n",
    "for this_alpha in [0.01, 0.1, 1.0, 5.0]:\n",
    "    for this_activation in ['relu', 'tanh', 'logistic']:\n",
    "        for this_solver in ['lbfgs', 'adam']:\n",
    "            clf = MLPClassifier(solver=this_solver, \n",
    "                        activation = this_activation,\n",
    "                        alpha = this_alpha,\n",
    "                        hidden_layer_sizes = [10,10,10], \n",
    "                        random_state = 0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            title = 'Dataset 2: NN classifier, alpha = {:.3f} '.format(this_alpha)\n",
    "            print(\"with   |  Solver: \", this_solver , \" | Activation: \" , this_activation,\" | Alpha: \", this_alpha)\n",
    "            print(title)\n",
    "            print(\"\\nTrain_score: %.3f\" % clf.score(X_train, y_train))\n",
    "            print(\"Test_score: %.3f\\n\" % clf.score(X_test, y_test))\n",
    "            print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layer and units 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.967\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.971\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.960\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.970\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.960\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.998\n",
      "Test_score: 0.973\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.968\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.992\n",
      "Test_score: 0.974\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.962\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.991\n",
      "Test_score: 0.973\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.961\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.971\n",
      "Test_score: 0.959\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.967\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.958\n",
      "Test_score: 0.950\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.965\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.948\n",
      "Test_score: 0.940\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.999\n",
      "Test_score: 0.969\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.907\n",
      "Test_score: 0.899\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.999\n",
      "Test_score: 0.969\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.905\n",
      "Test_score: 0.900\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.969\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.902\n",
      "Test_score: 0.895\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.993\n",
      "Test_score: 0.970\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.851\n",
      "Test_score: 0.847\n",
      "\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "#hidden layer and units 50\n",
    "for this_alpha in [0.01, 0.1, 1.0, 5.0]:\n",
    "    for this_activation in ['relu', 'tanh', 'logistic']:\n",
    "        for this_solver in ['lbfgs', 'adam']:\n",
    "            clf = MLPClassifier(solver=this_solver, \n",
    "                        activation = this_activation,\n",
    "                        alpha = this_alpha,\n",
    "                        hidden_layer_sizes = 50, \n",
    "                        random_state = 0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            title = 'Dataset 2: NN classifier, alpha = {:.3f} '.format(this_alpha)\n",
    "            print(\"with   |  Solver: \", this_solver , \" | Activation: \" , this_activation,\" | Alpha: \", this_alpha)\n",
    "            print(title)\n",
    "            print(\"\\nTrain_score: %.3f\" % clf.score(X_train, y_train))\n",
    "            print(\"Test_score: %.3f\\n\" % clf.score(X_test, y_test))\n",
    "            print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layer and units 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.974\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.998\n",
      "Test_score: 0.976\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.966\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.976\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.969\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.999\n",
      "Test_score: 0.978\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.975\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.994\n",
      "Test_score: 0.978\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.968\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.993\n",
      "Test_score: 0.977\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.969\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.972\n",
      "Test_score: 0.962\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.976\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.961\n",
      "Test_score: 0.953\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.971\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.950\n",
      "Test_score: 0.944\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.974\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.907\n",
      "Test_score: 0.901\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.977\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.910\n",
      "Test_score: 0.904\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 1.000\n",
      "Test_score: 0.976\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.900\n",
      "Test_score: 0.893\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.996\n",
      "Test_score: 0.977\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.838\n",
      "Test_score: 0.834\n",
      "\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "#hidden layer and units 100\n",
    "for this_alpha in [0.01, 0.1, 1.0, 5.0]:\n",
    "    for this_activation in ['relu', 'tanh', 'logistic']:\n",
    "        for this_solver in ['lbfgs', 'adam']:\n",
    "            clf = MLPClassifier(solver=this_solver, \n",
    "                        activation = this_activation,\n",
    "                        alpha = this_alpha,\n",
    "                        hidden_layer_sizes = 100, \n",
    "                        random_state = 0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            title = 'Dataset 2: NN classifier, alpha = {:.3f} '.format(this_alpha)\n",
    "            print(\"with   |  Solver: \", this_solver , \" | Activation: \" , this_activation,\" | Alpha: \", this_alpha)\n",
    "            print(title)\n",
    "            print(\"\\nTrain_score: %.3f\" % clf.score(X_train, y_train))\n",
    "            print(\"Test_score: %.3f\\n\" % clf.score(X_test, y_test))\n",
    "            print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layer and units [10,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.948\n",
      "Test_score: 0.938\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.986\n",
      "Test_score: 0.946\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.968\n",
      "Test_score: 0.936\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.984\n",
      "Test_score: 0.942\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.950\n",
      "Test_score: 0.930\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.01\n",
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "\n",
      "Train_score: 0.967\n",
      "Test_score: 0.941\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.947\n",
      "Test_score: 0.935\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.976\n",
      "Test_score: 0.957\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.968\n",
      "Test_score: 0.936\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.965\n",
      "Test_score: 0.943\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.951\n",
      "Test_score: 0.930\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  0.1\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "\n",
      "Train_score: 0.946\n",
      "Test_score: 0.935\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.949\n",
      "Test_score: 0.935\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.947\n",
      "Test_score: 0.938\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.967\n",
      "Test_score: 0.937\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.939\n",
      "Test_score: 0.930\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.952\n",
      "Test_score: 0.932\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  1.0\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "\n",
      "Train_score: 0.884\n",
      "Test_score: 0.878\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.950\n",
      "Test_score: 0.939\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  relu  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.901\n",
      "Test_score: 0.894\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.967\n",
      "Test_score: 0.939\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  tanh  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.893\n",
      "Test_score: 0.888\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  lbfgs  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.955\n",
      "Test_score: 0.935\n",
      "\n",
      "------------------------\n",
      "with   |  Solver:  adam  | Activation:  logistic  | Alpha:  5.0\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "\n",
      "Train_score: 0.112\n",
      "Test_score: 0.113\n",
      "\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "#hidden layer and units [10,100]\n",
    "for this_alpha in [0.01, 0.1, 1.0, 5.0]:\n",
    "    for this_activation in ['relu', 'tanh', 'logistic']:\n",
    "        for this_solver in ['lbfgs', 'adam']:\n",
    "            clf = MLPClassifier(solver=this_solver, \n",
    "                        activation = this_activation,\n",
    "                        alpha = this_alpha,\n",
    "                        hidden_layer_sizes = [10, 100], \n",
    "                        random_state = 0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            title = 'Dataset 2: NN classifier, alpha = {:.3f} '.format(this_alpha)\n",
    "            print(\"with   |  Solver: \", this_solver , \" | Activation: \" , this_activation,\" | Alpha: \", this_alpha)\n",
    "            print(title)\n",
    "            print(\"\\nTrain_score: %.3f\" % clf.score(X_train, y_train))\n",
    "            print(\"Test_score: %.3f\\n\" % clf.score(X_test, y_test))\n",
    "            print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering these results, looking at the overfit and underfit states between train and test scores, I decided to take it for the best score. We can list the parameters that have the best test score as follows:\n",
    "\n",
    "**Solver: adam, Activation: relu, Alpha: 0.1, Hidden_layer_sizes: 100**\n",
    "\n",
    "Train Score: 0.994\n",
    "\n",
    "Test Score: 0.978"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using GridSerchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'activation': ['tanh', 'relu', 'logistic'], 'alpha': [1.0, 0.5, 0.1, 0.01], 'hidden_layer_sizes': (10, [10, 10], [10, 10, 10], 50, 100, [10, 100])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "parameters = {'activation': ['tanh', 'relu', 'logistic'],\n",
    "              'alpha': [1.0, 0.5, 0.1, 0.01], \n",
    "              'hidden_layer_sizes': (10,[10,10],[10,10,10],50,100,[10,100])} \n",
    "clf_grid = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n",
    "clf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = clf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9759047619047619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 100}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification with the best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950285714285714"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(activation= 'relu', alpha= 0.1, hidden_layer_sizes=100).fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9767428571428571"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
